{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e0d3ea-44c0-4181-aa27-d38ab56d90b7",
   "metadata": {},
   "source": [
    "## Setup things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399b6102-9962-41df-9c73-41d0e43a53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "import httpx\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f08d96-d3f9-4c0d-90a8-ba37f2c604fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # OPENAI_API_KEY\n",
    "client = OpenAI() \n",
    "\n",
    "ARXIV_NAMESPACE = '{http://www.w3.org/2005/Atom}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd83a0-a06d-489e-a2f3-04d7f3a6a9db",
   "metadata": {},
   "source": [
    "## Check if OpenAI works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2757f8ff-f4fc-4bd4-96c4-1d4ec9206bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello there!\"}]\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0acb361b-8c2c-4330-9c90-b8ee25da3966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    \n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.run_llm()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def run_llm(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o\", \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8a1c34-9b32-4c99-ab57-557d56de0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "wikipedia:\n",
    "e.g. wikipedia:\n",
    "Returns a summary from searching Wikipedia\n",
    "\n",
    "arxiv_search:\n",
    "e.g. arxiv_search:\n",
    "Returns a summary of research papers\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the capital of France?\n",
    "Thought: I should look up France on Wikipedia\n",
    "Action: wikipedia: France\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: France is a country. The capital is Paris.\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: The capital of France is Paris\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6957f23c-287a-480d-bcc7-ec1bc2ffad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/sc/2r6rbq2x6zsd6hq3mjg5f73c0000gn/T/ipykernel_4148/3958739941.py:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  action_re = re.compile('^Action: (\\w+): (.*)$')\n"
     ]
    }
   ],
   "source": [
    "# abot = Agent(prompt)\n",
    "action_re = re.compile('^Action: (\\w+): (.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6dfd515-9880-4956-ab29-2aa5ef1396dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system_prompt=\"\", max_turns=1, known_actions=None):\n",
    "        self.max_turns = max_turns\n",
    "        self.bot = ChatBot(system_prompt)\n",
    "        self.known_actions = known_actions\n",
    "        \n",
    "    def run(self, question):\n",
    "        i = 0\n",
    "        next_prompt = question\n",
    "        \n",
    "        while i < self.max_turns:\n",
    "            i += 1\n",
    "            result = self.bot(next_prompt)\n",
    "            print(result)\n",
    "            actions = [action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
    "            if actions:\n",
    "                # There is an action to run\n",
    "                action, action_input = actions[0].groups()\n",
    "                if action not in self.known_actions:\n",
    "                    raise Exception(\"Unknown action: {}: {}\".format(action, action_input))\n",
    "                print(\" -- running {} {}\".format(action, action_input))\n",
    "                observation = self.known_actions[action](action_input)\n",
    "                print(\"Observation:\", observation)\n",
    "                next_prompt = \"Observation: {}\".format(observation)\n",
    "            else:\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402165c7-f09b-4e7d-a39e-8e0b875809b6",
   "metadata": {},
   "source": [
    "## Tools / Actions at the disposal of the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03e202d7-af14-4491-911b-d63ae1fe9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wikipedia(q):\n",
    "    return httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": q,\n",
    "        \"format\": \"json\"\n",
    "    }).json()[\"query\"][\"search\"][0][\"snippet\"]\n",
    "\n",
    "\n",
    "def arxiv_search(q):\n",
    "    url = f'http://export.arxiv.org/api/query?search_query=all:{q}&start=0&max_results=1'\n",
    "    res = requests.get(url)\n",
    "    et_root = ET.fromstring(res.content)\n",
    "    for entry in et_root.findall(f\"{ARXIV_NAMESPACE}entry\"):\n",
    "        title = entry.find(f\"{ARXIV_NAMESPACE}title\").text.strip()\n",
    "        summary = entry.find(f\"{ARXIV_NAMESPACE}summary\").text.strip()\n",
    "    return json.dumps({\"title\" : title, \"summary\" : summary})\n",
    "\n",
    "\n",
    "def calculate(what):\n",
    "    return eval(what)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9756e-dbe8-40c0-a186-5ce5f8e92d49",
   "metadata": {},
   "source": [
    "## Test our Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f62b06be-269e-4107-8d44-2c23c8dd3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up Indonesia on Wikipedia to find out its capital.\n",
      "Action: wikipedia: Indonesia\n",
      "PAUSE\n",
      " -- running wikipedia Indonesia\n",
      "Observation: <span class=\"searchmatch\">Indonesia</span>, officially the Republic of <span class=\"searchmatch\">Indonesia</span>, is a country in Southeast Asia and Oceania, between the Indian and Pacific oceans. Comprising over 17\n",
      "Answer: The capital of Indonesia is Jakarta.\n"
     ]
    }
   ],
   "source": [
    "known_actions = {\n",
    "    \"wikipedia\": wikipedia,\n",
    "    \"calculate\": calculate,\n",
    "    \"arxiv_search\": arxiv_search\n",
    "}\n",
    "agent = Agent(prompt, max_turns=3, known_actions=known_actions)\n",
    "agent.run(\"what is the capital of indonesia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb01ada6-c89e-465f-877b-fcb0fe87c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to calculate the sum of 7 and 5.\n",
      "Action: calculate: 7 + 5\n",
      "PAUSE\n",
      " -- running calculate 7 + 5\n",
      "Observation: 12\n",
      "Answer: The sum of 7 and 5 is 12.\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"what is the sum of 7 and 5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8be1370-2d36-4d28-abbd-38d25bc27ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should search for the \"lightrag paper\" to find relevant information about it, as it seems to be a specific research topic or publication.\n",
      "Action: arxiv_search: lightrag\n",
      "PAUSE\n",
      " -- running arxiv_search lightrag\n",
      "Observation: {\"title\": \"LightRAG: Simple and Fast Retrieval-Augmented Generation\", \"summary\": \"Retrieval-Augmented Generation (RAG) systems enhance large language models\\n(LLMs) by integrating external knowledge sources, enabling more accurate and\\ncontextually relevant responses tailored to user needs. However, existing RAG\\nsystems have significant limitations, including reliance on flat data\\nrepresentations and inadequate contextual awareness, which can lead to\\nfragmented answers that fail to capture complex inter-dependencies. To address\\nthese challenges, we propose LightRAG, which incorporates graph structures into\\ntext indexing and retrieval processes. This innovative framework employs a\\ndual-level retrieval system that enhances comprehensive information retrieval\\nfrom both low-level and high-level knowledge discovery. Additionally, the\\nintegration of graph structures with vector representations facilitates\\nefficient retrieval of related entities and their relationships, significantly\\nimproving response times while maintaining contextual relevance. This\\ncapability is further enhanced by an incremental update algorithm that ensures\\nthe timely integration of new data, allowing the system to remain effective and\\nresponsive in rapidly changing data environments. Extensive experimental\\nvalidation demonstrates considerable improvements in retrieval accuracy and\\nefficiency compared to existing approaches. We have made our LightRAG\\nopen-source and available at the link: https://github.com/HKUDS/LightRAG\"}\n",
      "Answer: The LightRAG paper, titled \"LightRAG: Simple and Fast Retrieval-Augmented Generation,\" presents a system that enhances large language models by integrating external knowledge sources. This approach aims to provide more accurate and contextually relevant responses. LightRAG addresses limitations in existing Retrieval-Augmented Generation (RAG) systems, such as reliance on flat data representations and inadequate contextual awareness, which can lead to fragmented answers. It incorporates graph structures into text indexing and retrieval processes, employing a dual-level retrieval system for comprehensive information retrieval. This system improves response times and maintains contextual relevance by efficiently retrieving related entities and their relationships. LightRAG also features an incremental update algorithm for timely integration of new data, ensuring effectiveness in rapidly changing environments. The paper reports significant improvements in retrieval accuracy and efficiency, and the LightRAG system is available as open-source at the provided GitHub link.\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"explain the lightrag paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6b9bc6f-2bab-4b0a-9cc9-3121d6077d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: \"AI Bites\" could refer to a variety of topics, such as a series of short educational pieces on artificial intelligence, a podcast, or a specific concept within AI. To provide a more accurate answer, I should look up \"AI Bites\" to see if it is a recognized term or series. \n",
      "Action: wikipedia: AI Bites\n",
      "PAUSE\n",
      " -- running wikipedia AI Bites\n",
      "Observation: &quot;Retrieval Augmented Generation(RAG) â€” A quick and comprehensive introduction&quot;. <span class=\"searchmatch\">ai</span>-<span class=\"searchmatch\">bites</span>.net. Kiela Douwe, Ho Alan (Oct 13, 2023). &quot;Where did Retrieval Augmented\n",
      "Thought: It seems that \"AI Bites\" might be related to a website or series that discusses topics in artificial intelligence, such as Retrieval Augmented Generation (RAG). To provide a more comprehensive answer, I should search for more information on \"AI Bites\" to understand its context and purpose. \n",
      "Action: arxiv_search: AI Bites\n",
      "PAUSE\n",
      " -- running arxiv_search AI Bites\n",
      "Observation: {\"title\": \"AI Progress in Skin Lesion Analysis\", \"summary\": \"We examine progress in the use of AI for detecting skin lesions, with\\nparticular emphasis on the erythema migrans rash of acute Lyme disease, and\\nother lesions, such as those from conditions like herpes zoster (shingles),\\ntinea corporis, erythema multiforme, cellulitis, insect bites, or tick bites.\\nWe discuss important challenges for these applications, in particular the\\nproblems of AI bias regarding the lack of skin images in dark skinned\\nindividuals, being able to accurately detect, delineate, and segment lesions or\\nregions of interest compared to normal skin in images, and low shot learning\\n(addressing classification with a paucity of training images). Solving these\\nproblems ranges from being highly desirable requirements -- e.g. for\\ndelineation, which may be useful to disambiguate between similar types of\\nlesions, and perform improved diagnostics -- or required, as is the case for AI\\nde-biasing, to allow for the deployment of fair AI techniques in the clinic for\\nskin lesion analysis. For the problem of low shot learning in particular, we\\nreport skin analysis algorithms that gracefully degrade and still perform well\\nat low shots, when compared to baseline algorithms: when using a little as 10\\ntraining exemplars per class, the baseline DL algorithm performance\\nsignificantly degrades, with accuracy of 56.41%, close to chance, whereas the\\nbest performing low shot algorithm yields an accuracy of 85.26%.\"}\n",
      "Thought: The search did not return specific information about \"AI Bites\" as a series or concept. It seems that \"AI Bites\" might not be a widely recognized term in academic literature or it could be a niche topic. Based on the initial observation, it might be related to a website or blog that discusses AI topics like Retrieval Augmented Generation. \n",
      "\n",
      "Answer: \"AI Bites\" appears to be related to a website or series that discusses topics in artificial intelligence, such as Retrieval Augmented Generation (RAG). It may not be a widely recognized term in academic literature, but it could be a niche source of information on AI topics.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(prompt, max_turns=3, known_actions=known_actions)\n",
    "agent.run(\"AI Bites\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
